{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aztofighi/LLM-Essay-Creator/blob/main/Create_AI_generated_essays_using_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPviDHEUHlI3",
        "outputId": "743fa7d2-4c95-43fc-e1c4-dde146dd4b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TWScnwsdHva_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db552a8-a2e5-4a70-8903-67259c5b6316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: condacolab: command not found\n",
            "Restarting of kernel...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!condacolab KERNEL RESTART\n",
        "print(\"Restarting of kernel...\")\n",
        "get_ipython().kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-bibHA3HHzSG"
      },
      "outputs": [],
      "source": [
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K7QHlj3iwkRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5742332-6689-45c3-f8b0-1a9aa6e5c1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install faker --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn_vgRgq4DBD",
        "outputId": "8f9fd672-7ba3-490f-936e-367832aa7e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "CUDA Version: 12.1\n",
            "Pytorch 2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "print(f\"Pytorch {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4FYISfDg4FKS"
      },
      "outputs": [],
      "source": [
        "import sys, random, string, re, time, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from tqdm.auto import tqdm\n",
        "from faker import Faker  #generates fake data\n",
        "from spacy.lang.en import English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F-GFGeD94KYJ"
      },
      "outputs": [],
      "source": [
        "import torch, random\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "SEED = 42\n",
        "# Seed the same seed to all\n",
        "def seed_everything(seed=42):\n",
        "    Faker.seed(0)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HBoa6HIC4NZq"
      },
      "outputs": [],
      "source": [
        "import ctypes, gc, torch\n",
        "libc = ctypes.CDLL(\"libc.so.6\")\n",
        "def clear_memory():\n",
        "    libc.malloc_trim(0)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k9kJBq9j4Wy7"
      },
      "outputs": [],
      "source": [
        "# Random generate 12 random number\n",
        "def get_userid(length=16):\n",
        "    \"\"\"Generate userid - \"\"\"\n",
        "    userid = str(int(np.random.rand()*1_000_000_000))\n",
        "    # Add the extra rand chars\n",
        "    for i in range(length):\n",
        "        # Select random char or digital number (0-9)\n",
        "        userid = userid + random.choice(string.ascii_letters + str(random.randint(0, 9)))\n",
        "    return userid\n",
        "\n",
        "# Generate the personal url from social media\n",
        "def generate_fake_social_media_url(user_name):\n",
        "    social_media_platforms = {\n",
        "        'LinkedIn': 'linkedin.com/in/',\n",
        "        'YouTube': 'youtube.com/c/',\n",
        "        'Instagram': 'instagram.com/',\n",
        "        'GitHub': 'github.com/',\n",
        "        'Facebook': 'facebook.com/',\n",
        "        'Twitter': 'twitter.com/'\n",
        "    }\n",
        "    platform, domain = random.choice(list(social_media_platforms.items()))\n",
        "    fake_url = f'https://{domain}{user_name}'\n",
        "    return fake_url\n",
        "\n",
        "def generate_username(first_name, last_name, fake_user_name):\n",
        "    \"\"\"usernames are created from first_name and last_name\"\"\"\n",
        "    SEPS = [\"_\", \".\", \"\"]\n",
        "    if random.choice([False, True]):\n",
        "        username = f\"{first_name.lower()}{random.choice(SEPS)}{last_name.lower()}{random.randint(1,999)}\"\n",
        "    else:\n",
        "        username = fake_user_name\n",
        "    return username\n",
        "\n",
        "def generate_email(first_name, last_name, faker):\n",
        "    \"\"\"usernames are created from first_name and last_name\"\"\"\n",
        "    SEPS = [\"_\", \".\", \"\"]\n",
        "    if random.choice([False, True]):\n",
        "        email = f\"{first_name.lower()}{random.choice(SEPS)}{last_name.lower()}@{faker.domain_name()}\"\n",
        "    else:\n",
        "        email = faker.email()\n",
        "    return email\n",
        "\n",
        "def generate_student_info():\n",
        "    \"\"\"Generates all the user info (name, eamil addresses, phone number, etc) together \"\"\"\n",
        "    # Select the student country to generate the user info based on the country\n",
        "    COUNTRIES = [\"en_US\", \"en_US\", \"en_US\", \"en_US\", \"en_US\", \"en_US\",\n",
        "                 \"de_DE\", \"it_IT\", \"es_ES\", \"da_DK\", \"fr_FR\", \"vi_VN\"]\n",
        "    country = random.choice(COUNTRIES)\n",
        "    faker = Faker(country)\n",
        "    first_name = faker.first_name()\n",
        "    last_name = faker.last_name()\n",
        "    user_name = generate_username(first_name, last_name, faker.user_name())\n",
        "    fake_url = generate_fake_social_media_url(user_name)\n",
        "    student = {}\n",
        "    student['COUNTRY'] = country\n",
        "    student['ID_NUM'] = get_userid() # User ID\n",
        "    student['NAME_STUDENT'] = first_name + \" \"+  last_name\n",
        "    student['EMAIL'] = generate_email(first_name, last_name, faker)\n",
        "    student['USERNAME'] = user_name\n",
        "    student['PHONE_NUM'] = faker.phone_number().replace(\" \", \"\")\n",
        "    student['URL_PERSONAL'] = fake_url\n",
        "    student['STREET_ADDRESS'] = str(faker.address()).replace(\"\\n\",\" \") # Replace \\n with space in the address\n",
        "    del faker\n",
        "    clear_memory()\n",
        "#     print(student)\n",
        "    return student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5cb969d61b874891848e63e48644c6f0",
            "5fe4f31be673447dabcb40313c0c62ca",
            "abf4ba9bcdc34f0db15d91fdccb86844",
            "d991d906dd724703b87fbf3c1d9cf764",
            "7668c44a68d946fb931d51a251329aa9",
            "e1ac2735f5374e209dd38d9fab22bdfa",
            "cc1c412f288d478aa364fc3fe4fb6111",
            "7fed3cd73b3a47bebacf57945c49609f",
            "e662454e695b456d9a5c4fd2049b446e",
            "ffbb7d31157e46b6a21df97898c405d9",
            "6899348464ec4690836c02c18eac3782"
          ]
        },
        "id": "MhiqykCx67fp",
        "outputId": "0aa0bd00-484f-4693-c990-56393132446c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cb969d61b874891848e63e48644c6f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate 0-th information\n",
            "Generate 1-th information\n",
            "Generate 2-th information\n",
            "Generate 3-th information\n",
            "Generate 4-th information\n",
            "Generate 5-th information\n",
            "Generate 6-th information\n",
            "Generate 7-th information\n",
            "Generate 8-th information\n",
            "Generate 9-th information\n",
            "Generate 10-th information\n",
            "Generate 11-th information\n",
            "Generate 12-th information\n",
            "Generate 13-th information\n",
            "Generate 14-th information\n",
            "Generate 15-th information\n",
            "Generate 16-th information\n",
            "Generate 17-th information\n",
            "Generate 18-th information\n",
            "Generate 19-th information\n",
            "Generate 20-th information\n",
            "Generate 21-th information\n",
            "Generate 22-th information\n",
            "Generate 23-th information\n",
            "Generate 24-th information\n",
            "Generate 25-th information\n",
            "Generate 26-th information\n",
            "Generate 27-th information\n",
            "Generate 28-th information\n",
            "Generate 29-th information\n",
            "Generate 30-th information\n",
            "Generate 31-th information\n",
            "Generate 32-th information\n",
            "Generate 33-th information\n",
            "Generate 34-th information\n",
            "Generate 35-th information\n",
            "Generate 36-th information\n",
            "Generate 37-th information\n",
            "Generate 38-th information\n",
            "Generate 39-th information\n",
            "Generate 40-th information\n",
            "Generate 41-th information\n",
            "Generate 42-th information\n",
            "Generate 43-th information\n",
            "Generate 44-th information\n",
            "Generate 45-th information\n",
            "Generate 46-th information\n",
            "Generate 47-th information\n",
            "Generate 48-th information\n",
            "Generate 49-th information\n",
            "Generate 50-th information\n",
            "Generate 51-th information\n",
            "Generate 52-th information\n",
            "Generate 53-th information\n",
            "Generate 54-th information\n",
            "Generate 55-th information\n",
            "Generate 56-th information\n",
            "Generate 57-th information\n",
            "Generate 58-th information\n",
            "Generate 59-th information\n",
            "Generate 60-th information\n",
            "Generate 61-th information\n",
            "Generate 62-th information\n",
            "Generate 63-th information\n",
            "Generate 64-th information\n",
            "Generate 65-th information\n",
            "Generate 66-th information\n",
            "Generate 67-th information\n",
            "Generate 68-th information\n",
            "Generate 69-th information\n",
            "Generate 70-th information\n",
            "Generate 71-th information\n",
            "Generate 72-th information\n",
            "Generate 73-th information\n",
            "Generate 74-th information\n",
            "Generate 75-th information\n",
            "Generate 76-th information\n",
            "Generate 77-th information\n",
            "Generate 78-th information\n",
            "Generate 79-th information\n",
            "Generate 80-th information\n",
            "Generate 81-th information\n",
            "Generate 82-th information\n",
            "Generate 83-th information\n",
            "Generate 84-th information\n",
            "Generate 85-th information\n",
            "Generate 86-th information\n",
            "Generate 87-th information\n",
            "Generate 88-th information\n",
            "Generate 89-th information\n",
            "Generate 90-th information\n",
            "Generate 91-th information\n",
            "Generate 92-th information\n",
            "Generate 93-th information\n",
            "Generate 94-th information\n",
            "Generate 95-th information\n",
            "Generate 96-th information\n",
            "Generate 97-th information\n",
            "Generate 98-th information\n",
            "Generate 99-th information\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   COUNTRY                     ID_NUM       NAME_STUDENT  \\\n",
              "90   en_US  119594245AiylOSJFiuNwFmJP        Melvin Rowe   \n",
              "91   fr_FR  713244787kKYsrIkKJhhX8IWI  Christiane Wagner   \n",
              "92   de_DE  760785048tCwCXnSTOki3ZKIM   Gundula Losekann   \n",
              "93   en_US  561277197RidPSpTpFKOyezVS      Deborah White   \n",
              "94   it_IT  770967179UOezBFuvKKYRcObk   Lando Mascheroni   \n",
              "95   en_US  493795596kfqxdOUBTaEioRaS    Courtney Mullen   \n",
              "96   de_DE  522732829ofgxiXPeKNCUOARn      Margot Etzold   \n",
              "97   en_US  427541018UwupPpMUsQnMmsYF  Samantha Williams   \n",
              "98   en_US   25419126auyAIWXbeqcYGOXB       Dawn Mullins   \n",
              "99   fr_FR  107891426tGZIzOtUdfhNdQhT   Philippe Schmitt   \n",
              "\n",
              "                                EMAIL              USERNAME  \\\n",
              "90         melvin.rowe@day-watson.org     natashamccullough   \n",
              "91            veronique67@example.net  christiane.wagner728   \n",
              "92               walter85@example.com                xtrueb   \n",
              "93  deborah.white@sanders-collins.net      deborah.white587   \n",
              "94     lando.mascheroni@battaglia.com      landomascheroni3   \n",
              "95      courtney_mullen@kemp-rice.com    courtney_mullen706   \n",
              "96            margareta53@example.net           gerlachsina   \n",
              "97        samantha_williams@ayala.com            jennifer56   \n",
              "98     dawn_mullins@watkins-nixon.com        dawnmullins609   \n",
              "99                ilebrun@example.net              hboucher   \n",
              "\n",
              "               PHONE_NUM                              URL_PERSONAL  \\\n",
              "90  001-443-201-7823x695    https://facebook.com/natashamccullough   \n",
              "91            0183015666   https://github.com/christiane.wagner728   \n",
              "92            0925067741                https://twitter.com/xtrueb   \n",
              "93            6278211744    https://instagram.com/deborah.white587   \n",
              "94          +39012582111      https://twitter.com/landomascheroni3   \n",
              "95       +1-898-764-3912  https://youtube.com/c/courtney_mullen706   \n",
              "96      +49(0)8724531935            https://github.com/gerlachsina   \n",
              "97  +1-824-658-1273x9991        https://linkedin.com/in/jennifer56   \n",
              "98     (910)865-2736x903    https://linkedin.com/in/dawnmullins609   \n",
              "99            0767149544            https://instagram.com/hboucher   \n",
              "\n",
              "                                       STREET_ADDRESS  \n",
              "90  5039 Carlos Curve Apt. 886 Jaredchester, AK 71876  \n",
              "91                96, avenue Bousquet 36789 Brunetnec  \n",
              "92                  Pierre-Barth-Weg 2 71129 Geithain  \n",
              "93  7104 Sarah Motorway Suite 836 South Billyland,...  \n",
              "94  Strada Carosone, 7 Appartamento 95 34076, Mede...  \n",
              "95  500 Douglas Streets Apt. 221 Navarroberg, KY 3...  \n",
              "96                      Wohlgemutstraße 0 36068 Ebern  \n",
              "97               0092 Jackson Lodge New Amy, ID 04639  \n",
              "98  66734 Jacqueline Estate West Rhondaburgh, CT 2...  \n",
              "99             880, boulevard de Gaudin 25532 Foucher  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12c55d65-5e69-4e4b-8c99-b2d5823ee6da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTRY</th>\n",
              "      <th>ID_NUM</th>\n",
              "      <th>NAME_STUDENT</th>\n",
              "      <th>EMAIL</th>\n",
              "      <th>USERNAME</th>\n",
              "      <th>PHONE_NUM</th>\n",
              "      <th>URL_PERSONAL</th>\n",
              "      <th>STREET_ADDRESS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>en_US</td>\n",
              "      <td>119594245AiylOSJFiuNwFmJP</td>\n",
              "      <td>Melvin Rowe</td>\n",
              "      <td>melvin.rowe@day-watson.org</td>\n",
              "      <td>natashamccullough</td>\n",
              "      <td>001-443-201-7823x695</td>\n",
              "      <td>https://facebook.com/natashamccullough</td>\n",
              "      <td>5039 Carlos Curve Apt. 886 Jaredchester, AK 71876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>fr_FR</td>\n",
              "      <td>713244787kKYsrIkKJhhX8IWI</td>\n",
              "      <td>Christiane Wagner</td>\n",
              "      <td>veronique67@example.net</td>\n",
              "      <td>christiane.wagner728</td>\n",
              "      <td>0183015666</td>\n",
              "      <td>https://github.com/christiane.wagner728</td>\n",
              "      <td>96, avenue Bousquet 36789 Brunetnec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>de_DE</td>\n",
              "      <td>760785048tCwCXnSTOki3ZKIM</td>\n",
              "      <td>Gundula Losekann</td>\n",
              "      <td>walter85@example.com</td>\n",
              "      <td>xtrueb</td>\n",
              "      <td>0925067741</td>\n",
              "      <td>https://twitter.com/xtrueb</td>\n",
              "      <td>Pierre-Barth-Weg 2 71129 Geithain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>en_US</td>\n",
              "      <td>561277197RidPSpTpFKOyezVS</td>\n",
              "      <td>Deborah White</td>\n",
              "      <td>deborah.white@sanders-collins.net</td>\n",
              "      <td>deborah.white587</td>\n",
              "      <td>6278211744</td>\n",
              "      <td>https://instagram.com/deborah.white587</td>\n",
              "      <td>7104 Sarah Motorway Suite 836 South Billyland,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>it_IT</td>\n",
              "      <td>770967179UOezBFuvKKYRcObk</td>\n",
              "      <td>Lando Mascheroni</td>\n",
              "      <td>lando.mascheroni@battaglia.com</td>\n",
              "      <td>landomascheroni3</td>\n",
              "      <td>+39012582111</td>\n",
              "      <td>https://twitter.com/landomascheroni3</td>\n",
              "      <td>Strada Carosone, 7 Appartamento 95 34076, Mede...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>en_US</td>\n",
              "      <td>493795596kfqxdOUBTaEioRaS</td>\n",
              "      <td>Courtney Mullen</td>\n",
              "      <td>courtney_mullen@kemp-rice.com</td>\n",
              "      <td>courtney_mullen706</td>\n",
              "      <td>+1-898-764-3912</td>\n",
              "      <td>https://youtube.com/c/courtney_mullen706</td>\n",
              "      <td>500 Douglas Streets Apt. 221 Navarroberg, KY 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>de_DE</td>\n",
              "      <td>522732829ofgxiXPeKNCUOARn</td>\n",
              "      <td>Margot Etzold</td>\n",
              "      <td>margareta53@example.net</td>\n",
              "      <td>gerlachsina</td>\n",
              "      <td>+49(0)8724531935</td>\n",
              "      <td>https://github.com/gerlachsina</td>\n",
              "      <td>Wohlgemutstraße 0 36068 Ebern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>en_US</td>\n",
              "      <td>427541018UwupPpMUsQnMmsYF</td>\n",
              "      <td>Samantha Williams</td>\n",
              "      <td>samantha_williams@ayala.com</td>\n",
              "      <td>jennifer56</td>\n",
              "      <td>+1-824-658-1273x9991</td>\n",
              "      <td>https://linkedin.com/in/jennifer56</td>\n",
              "      <td>0092 Jackson Lodge New Amy, ID 04639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>en_US</td>\n",
              "      <td>25419126auyAIWXbeqcYGOXB</td>\n",
              "      <td>Dawn Mullins</td>\n",
              "      <td>dawn_mullins@watkins-nixon.com</td>\n",
              "      <td>dawnmullins609</td>\n",
              "      <td>(910)865-2736x903</td>\n",
              "      <td>https://linkedin.com/in/dawnmullins609</td>\n",
              "      <td>66734 Jacqueline Estate West Rhondaburgh, CT 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>fr_FR</td>\n",
              "      <td>107891426tGZIzOtUdfhNdQhT</td>\n",
              "      <td>Philippe Schmitt</td>\n",
              "      <td>ilebrun@example.net</td>\n",
              "      <td>hboucher</td>\n",
              "      <td>0767149544</td>\n",
              "      <td>https://instagram.com/hboucher</td>\n",
              "      <td>880, boulevard de Gaudin 25532 Foucher</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12c55d65-5e69-4e4b-8c99-b2d5823ee6da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12c55d65-5e69-4e4b-8c99-b2d5823ee6da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12c55d65-5e69-4e4b-8c99-b2d5823ee6da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76f70433-0717-4377-a636-37b998410eea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76f70433-0717-4377-a636-37b998410eea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76f70433-0717-4377-a636-37b998410eea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    shutil\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"COUNTRY\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"fr_FR\",\n          \"it_IT\",\n          \"en_US\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ID_NUM\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"25419126auyAIWXbeqcYGOXB\",\n          \"713244787kKYsrIkKJhhX8IWI\",\n          \"493795596kfqxdOUBTaEioRaS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME_STUDENT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Dawn Mullins\",\n          \"Christiane Wagner\",\n          \"Courtney Mullen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EMAIL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"dawn_mullins@watkins-nixon.com\",\n          \"veronique67@example.net\",\n          \"courtney_mullen@kemp-rice.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"USERNAME\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"dawnmullins609\",\n          \"christiane.wagner728\",\n          \"courtney_mullen706\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHONE_NUM\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"(910)865-2736x903\",\n          \"0183015666\",\n          \"+1-898-764-3912\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL_PERSONAL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://linkedin.com/in/dawnmullins609\",\n          \"https://github.com/christiane.wagner728\",\n          \"https://youtube.com/c/courtney_mullen706\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"STREET_ADDRESS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"66734 Jacqueline Estate West Rhondaburgh, CT 20715\",\n          \"96, avenue Bousquet 36789 Brunetnec\",\n          \"500 Douglas Streets Apt. 221 Navarroberg, KY 34677\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "# Copy the generated df to working folder\n",
        "import shutil\n",
        "\n",
        "GENERATED = True\n",
        "# Create the folder\n",
        "Path(\"/content\").mkdir(parents=True, exist_ok=True)\n",
        "if GENERATED:\n",
        "    TOTAL = 100 # Generate 100\n",
        "    students = []\n",
        "    for i in tqdm(range(TOTAL)):\n",
        "        students.append(generate_student_info())\n",
        "        print(f\"Generate {i}-th information\")\n",
        "    df = pd.DataFrame(students)\n",
        "    df = df.reset_index(drop=True)\n",
        "    # Save to the csv file\n",
        "    df.to_csv(\"/content/df.csv\", index=False, encoding='UTF-8') # Do not save default ID column\n",
        "    display(df.tail(10))\n",
        "    # Check if ID_NUM has any duplicates\n",
        "    assert df['ID_NUM'].duplicated().value_counts()[False] == TOTAL, \"Duplicated ID_NUM\"\n",
        "else:\n",
        "    shutil.copy('/kaggle/input/ai-generated-text-dataset/temp/df.csv', '/kaggle/working/temp/df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IARPBWJ6Bl_N",
        "outputId": "21deb4e0-38b0-4b4e-a706-cbf09800ed46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/mistral-ai/mistral/pyTorch/7b-instruct-v0.1-hf/1/download...\n",
            "100%|██████████| 11.1G/11.1G [02:21<00:00, 84.6MB/s]\n",
            "Extracting model files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to model files: /root/.cache/kagglehub/models/mistral-ai/mistral/pyTorch/7b-instruct-v0.1-hf/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.model_download(\"mistral-ai/mistral/pyTorch/7b-instruct-v0.1-hf\")\n",
        "\n",
        "print(\"Path to model files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tDDR69VE7BUP"
      },
      "outputs": [],
      "source": [
        "def load_model():\n",
        "    torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "    torch.backends.cuda.enable_flash_sdp(False)\n",
        "    model_path=\"/root/.cache/kagglehub/models/mistral-ai/mistral/pyTorch/7b-instruct-v0.1-hf/1\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_path,\n",
        "                                                 torch_dtype=torch.bfloat16,\n",
        "                                                 device_map=\"auto\")\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "12UfKWnN7Dnp"
      },
      "outputs": [],
      "source": [
        "def generate_on_user_info(row):\n",
        "    # Prompt template generates the texts\n",
        "    prompt_template = \"\"\"<s>[INST]\n",
        "    You are an essay writer.\n",
        "    You will be given some personal information about the student writing it, like\n",
        "    name = {first_name} {last_name}\n",
        "    email = {email}\n",
        "    street address = {address}\n",
        "    phone number = {phone_num}\n",
        "    personal url = {url}\n",
        "    username = {username}\n",
        "    user id = {userid}\n",
        "    You need to write a short essay that includes all the given information somewhere in the essay.\n",
        "    Do not miss out any.[/INST]\"\"\"\n",
        "\n",
        "    first_name = row['NAME_STUDENT'].split()[0]\n",
        "    last_name = row['NAME_STUDENT'].split()[1]\n",
        "    email = row['EMAIL']\n",
        "    phone_num = row['PHONE_NUM']\n",
        "    address = row['STREET_ADDRESS']\n",
        "    url = row['URL_PERSONAL']\n",
        "    username = row['USERNAME']\n",
        "    userid = row['ID_NUM']\n",
        "    # Fill in prompt with PII\n",
        "    prompt = prompt_template.format(first_name=first_name,\n",
        "                                    last_name=last_name,\n",
        "                                    email=email,\n",
        "                                    phone_num=phone_num,\n",
        "                                    address=address,\n",
        "                                    url=url,\n",
        "                                    username=username,\n",
        "                                    userid=userid\n",
        "                                   )\n",
        "    return prompt\n",
        "\n",
        "def generate_texts(model, tokenizer, df, num_essays):\n",
        "    generated_df = df[:num_essays]\n",
        "    # Generate the texts\n",
        "    for i in tqdm(range(len(generated_df))):\n",
        "        start = time.time()\n",
        "        # Generate PII\n",
        "        row = generated_df.loc[i]\n",
        "        # Generate the texts using three prompts\n",
        "        prompt = generate_on_user_info(row)\n",
        "        # Tokenize the prompt\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "        # Generate the outputs from prompt\n",
        "        generate_ids = model.generate(**inputs,\n",
        "                                      max_new_tokens=768,\n",
        "                                      do_sample=True,\n",
        "                                      temperature=0.7,\n",
        "                                      top_p=0.95,\n",
        "                                      top_k=40,\n",
        "                                      repetition_penalty=1.1,\n",
        "                                      pad_token_id=tokenizer.eos_token_id\n",
        "                                     )\n",
        "        # Decode the generated output\n",
        "        generated_text = tokenizer.batch_decode(generate_ids, skip_special_tokens=True,\n",
        "                                                 clean_up_tokenization_spaces=False)[0]\n",
        "        generated_text = generated_text.split('[/INST] ')[1]\n",
        "#         print(f\"generated_text = {generated_text}\" )\n",
        "        generated_df.loc[i, 'generated_text'] = generated_text\n",
        "        clear_memory()\n",
        "        print(f\"Complete the text for {i}-th student {time.time() - start: .1f} seconds\")\n",
        "    # Save generated_df to csv\n",
        "    generated_df.to_csv(\"temp/generated_df.csv\", index=False, encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "1wiO6KJL8Z1N",
        "outputId": "6b5f78a9-41c5-44d6-9d22-12062dcab704"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      COUNTRY         ID_NUM NAME_STUDENT                  EMAIL USERNAME  \\\n",
              "21678     NaN  ['001884899']               ['rherman@gmail.com']       []   \n",
              "\n",
              "                      PHONE_NUM                           URL_PERSONAL  \\\n",
              "21678  ['+1-810-639-5189x9133']  ['https://linkedin.com/in/william10']   \n",
              "\n",
              "      STREET_ADDRESS                                              Essay  \\\n",
              "21678             []  In the tapestry of life, personal experiences ...   \n",
              "\n",
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "21678        NaN       NaN                 NaN          NaN             NaN   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "21678         NaN         NaN            NaN                 NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb2e6b58-a6a9-456c-8dd4-1184e767a990\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTRY</th>\n",
              "      <th>ID_NUM</th>\n",
              "      <th>NAME_STUDENT</th>\n",
              "      <th>EMAIL</th>\n",
              "      <th>USERNAME</th>\n",
              "      <th>PHONE_NUM</th>\n",
              "      <th>URL_PERSONAL</th>\n",
              "      <th>STREET_ADDRESS</th>\n",
              "      <th>Essay</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21678</th>\n",
              "      <td>NaN</td>\n",
              "      <td>['001884899']</td>\n",
              "      <td></td>\n",
              "      <td>['rherman@gmail.com']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['+1-810-639-5189x9133']</td>\n",
              "      <td>['https://linkedin.com/in/william10']</td>\n",
              "      <td>[]</td>\n",
              "      <td>In the tapestry of life, personal experiences ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb2e6b58-a6a9-456c-8dd4-1184e767a990')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb2e6b58-a6a9-456c-8dd4-1184e767a990 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb2e6b58-a6a9-456c-8dd4-1184e767a990');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the generated df from Gemmafrom google.colab import files\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/Essay Creator/generated_df_0_100.csv', encoding='UTF-8')\n",
        "df2 = pd.read_csv('/content/sample_data/Essay Creator/generated_df_100_900.csv', encoding='UTF-8')\n",
        "df3 = pd.read_csv('/content/sample_data/california_housing_train.csv', encoding='UTF-8')\n",
        "generated_df = pd.concat([df, df2, df3])\n",
        "generated_df = generated_df.reset_index(drop=True, inplace=False)\n",
        "generated_df = generated_df.rename({'generated_text': 'Essay'}, axis=1)\n",
        "# Load the generated df from Gemini\n",
        "df4 = pd.read_csv('/content/sample_data/Essay Creator/pii_gemini.csv',encoding='UTF-8', index_col=[0]) # Load df without unnamed columns\n",
        "df4['NAME_STUDENT'] = ['' for _ in range(len(df4))] # The dataset lacks of student name\n",
        "df4 = df4.reset_index(drop=True, inplace=False)\n",
        "# Combine both datasets\n",
        "generated_df = pd.concat([generated_df, df4])\n",
        "# generated_df = df4\n",
        "generated_df = generated_df.reset_index(drop=True, inplace=False)\n",
        "display(generated_df.tail(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "d28e42dc4326427c93d9640e843b56ad",
            "5284cda3ff764f3e8dd116772e2b79c0",
            "9569f011af4146c8b936c26743330374",
            "fdc62045148f477ab33c16f418e7346c",
            "06fab88c074b487d8abe8688515680c8",
            "6984e7cb4f904203a74488e03eb1e423",
            "f1f1a9a9d4d343fa9d6820faf0fe4bd0",
            "d7f49b1affc54fb192cd70ab2b0c64c7",
            "d1ccd7c44794497f8b76ce4b92785fce",
            "5c934e5d6fe44d5d92ffd7d779815af5",
            "f2cd9f68b81944608f9b5092ee21c5f0"
          ]
        },
        "id": "q_UK0eKp8XUi",
        "outputId": "3f7f7e81-2356-43a6-ac04-a5b628c8d5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d28e42dc4326427c93d9640e843b56ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8bd199eeaddf>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(model_path,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                  \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                  \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3675\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3676\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3677\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3678\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3679\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   4102\u001b[0m                                 )\n\u001b[1;32m   4103\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4104\u001b[0;31m                         new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4105\u001b[0m                             \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4106\u001b[0m                             \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam_device\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"disk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_safetensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 \u001b[0moffload_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffload_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffload_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffload_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparam_device\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstate_dict_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0mstate_dict_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffload_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/offload.py\u001b[0m in \u001b[0;36moffload_weight\u001b[0;34m(weight, weight_name, offload_folder, index)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mfile_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfile_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mfile_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \"\"\"\n\u001b[1;32m    303\u001b[0m         \u001b[0mWrite\u001b[0m \u001b[0many\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marray\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mon\u001b[0m \u001b[0mdisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install safetensors # by me\n",
        "model_path=\"/root/.cache/kagglehub/models/mistral-ai/mistral/pyTorch/7b-instruct-v0.1-hf/1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path,\n",
        "                                                 torch_dtype=torch.bfloat16,\n",
        "                                                 device_map=\"auto\",\n",
        "                                                 offload_folder=\"/tmp/offload\")\n",
        "\n",
        "GENERATED = True  # True: Generate texts\n",
        "if GENERATED:\n",
        "    model, tokenizer = load_model()\n",
        "    generate_texts(model, tokenizer, df, num_essays=20)\n",
        "    sys.exit(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Cw_m8i7t8dDe"
      },
      "outputs": [],
      "source": [
        "label_types = ['NAME_STUDENT','EMAIL', 'USERNAME', 'ID_NUM',\n",
        "               'PHONE_NUM', 'URL_PERSONAL', 'STREET_ADDRESS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "S_Vb5piS8fPF"
      },
      "outputs": [],
      "source": [
        "from spacy.lang.en import English\n",
        "import re\n",
        "\n",
        "en_tokenizer = English().tokenizer\n",
        "\n",
        "def tokenize_with_spacy(text, tokenizer=en_tokenizer):\n",
        "    tokenized_text = tokenizer(text)\n",
        "    tokens = [token.text for token in tokenized_text]\n",
        "    trailing_whitespace = [bool(token.whitespace_) for token in tokenized_text]\n",
        "    return tokens, trailing_whitespace\n",
        "\n",
        "# Update labels and boolean flags\n",
        "def update_labels(i, token, label_type, labels, isFirst_flags):\n",
        "#     print(f\"Found {i}-th position token: {token}\")\n",
        "    # Update the label\n",
        "    if isFirst_flags[label_type]:\n",
        "        labels[i] = 'B-'+label_type # Beginning of an entity\n",
        "        isFirst_flags[label_type] = False\n",
        "    else:\n",
        "        labels[i] = 'I-'+label_type # Contiunity of an entity\n",
        "    return labels, isFirst_flags\n",
        "\n",
        "# Go through each token and assign name label ('NAME_STUDENT') if matched\n",
        "def assign_name(names, tokens, labels):\n",
        "    #print(f\"Search 'NAME_STUDENT': {names}\")\n",
        "    for i, token in enumerate(tokens):\n",
        "        token = str(token).lower()\n",
        "        # Order does not matter\n",
        "        if token in names:\n",
        "            # If the previous\n",
        "            if i > 0 and labels[i-1] == 'B-NAME_STUDENT':\n",
        "                labels[i] = 'I-NAME_STUDENT'\n",
        "            else:\n",
        "                labels[i] = 'B-NAME_STUDENT'\n",
        "    return labels\n",
        "\n",
        "def assign_phone_number(phones, tokens, labels, isFirst_flags):\n",
        "#     print(f\"Search 'PHONE_NUM': {phone_tokens}\")\n",
        "    for i, token in enumerate(tokens):\n",
        "        token_ = str(token).lower()\n",
        "        label = labels[i]\n",
        "        # Add a special case '-'\n",
        "        if token == '-':\n",
        "            # Check if the previous token is not 'O'\n",
        "            if labels[i-1] != 'O':\n",
        "                # Update the labels\n",
        "                labels, isFirst_flags = update_labels(i, token_, 'PHONE_NUM',\n",
        "                                                      labels, isFirst_flags)\n",
        "        else:\n",
        "            # Check if token is matched last name\n",
        "            if label == 'O' and token_ in phones:\n",
        "                labels, isFirst_flags = update_labels(i, token_, 'PHONE_NUM',\n",
        "                                                      labels, isFirst_flags)\n",
        "    return labels, isFirst_flags\n",
        "\n",
        "# Go through each token and assign street address label\n",
        "def assign_street_address(address, tokens, labels):\n",
        "    # print(tokens)\n",
        "    # Keep track of index for a long label\n",
        "    label_index = 0\n",
        "    reserve_indices = []\n",
        "    sandwich_max_size = 3\n",
        "    #print(f'address = {address}')\n",
        "    for i, token in enumerate(tokens):\n",
        "        try:\n",
        "            #Order matters and sandwiches are possible\n",
        "            token = str(token).lower()\n",
        "            curr_idx = label_index\n",
        "            curr_token = address[curr_idx]\n",
        "            if token == curr_token:\n",
        "                # print(f\"token = {token}\")\n",
        "                #case where a token corresponds to the expected next token\n",
        "                if len(reserve_indices) > sandwich_max_size:\n",
        "                    reserve_indices = []\n",
        "\n",
        "                prefix = 'B-' if curr_idx == 0 else 'I-'\n",
        "                labels[i] = prefix + 'STREET_ADDRESS'\n",
        "                #fill sandwiches if the next token has been found\n",
        "                for k in reserve_indices:\n",
        "                    labels[k] = 'I-STREET_ADDRESS'\n",
        "                reserve_indices = []\n",
        "                #Update positional pointer\n",
        "                label_index += 1\n",
        "                # At the end of address\n",
        "                if label_index == len(address):\n",
        "                    label_index = 0\n",
        "                # print(f'label_index = {label_index}')\n",
        "            else:\n",
        "                reserve_indices.append(i)\n",
        "                #print(f\"! {token}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurs at {i}-th {token} \\n{e}\" )\n",
        "            sys.exit(-1)\n",
        "#         #case where some surprise token has been added in the PII\n",
        "#     address_labels = [(label, token) for i, (label, token) in enumerate(zip(labels, tokens))\n",
        "#                       if label =='B-STREET_ADDRESS' or label == 'I-STREET_ADDRESS']\n",
        "#     print(address_labels)\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Assign labels for other types\n",
        "def assign_other_label_types(essay, label_type, tokens, labels, isFirst_flags):\n",
        "    label_value = essay[label_type].lower()\n",
        "#     print(f\"Search '{label_type}': {label_value}\")\n",
        "    for i, token in enumerate(tokens):\n",
        "        token_ = str(token).lower()\n",
        "        # Check if token is first or last name\n",
        "        if label_value in token_:\n",
        "            # Update the label\n",
        "            labels, isFirst_flags = update_labels(i, token_, label_type,\n",
        "                                                      labels, isFirst_flags)\n",
        "    return labels, isFirst_flags\n",
        "\n",
        "# Assign labels for other types\n",
        "def assign_email(email, tokens, labels):\n",
        "    #print(f\"Search Email: {email}\")\n",
        "    is_First = False\n",
        "    for i, token in enumerate(tokens):\n",
        "        token_ = str(token).lower()\n",
        "        # Check if token is first or last name\n",
        "        if email in token_:\n",
        "            # print(f'Token {token_}')\n",
        "            if not is_First:\n",
        "                # Update the label\n",
        "                labels[i] = 'B-EMAIL'\n",
        "                is_First = True\n",
        "            else: # Skip labeling\n",
        "                print(f\"Duplicated Email {email}\")\n",
        "    return labels\n",
        "\n",
        "# Assign labels for other types\n",
        "def assign_username(username, tokens, labels):\n",
        "    #print(f\"Search username: {username}\")\n",
        "    is_First = False\n",
        "    for i, token in enumerate(tokens):\n",
        "        token_ = str(token).lower()\n",
        "        # Check if token is first or last name\n",
        "        if username in token_:\n",
        "            # print(f'Token {token_}')\n",
        "            if not is_First:\n",
        "                # Update the label\n",
        "                labels[i] = 'B-USERNAME'\n",
        "                is_First = True\n",
        "            else: # Skip labeling\n",
        "                print(f\"Duplicated username {username}\")\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QqWNaPO_-OR0"
      },
      "outputs": [],
      "source": [
        "# “B-”: the beginning of an entity.\n",
        "# “I-”: the next of an entity\n",
        "def assign_labels(essay, tokens):\n",
        "    # print(f\"essay['NAME_STUDENT'] = {essay['NAME_STUDENT']}\" )\n",
        "    # Assign \"O\" to labels by default\n",
        "    labels = ['O' for token in tokens]\n",
        "    # Create a boolean flag list to track if a label type start the text.\n",
        "    isFirst_flags = {label_type: True for label_type in label_types}\n",
        "    # Go through each token and check if the label appear in the token\n",
        "    # All token and label values are lower case for comparison\n",
        "    for label_type in label_types:\n",
        "        if label_type == 'NAME_STUDENT':\n",
        "            if essay['NAME_STUDENT'] != '':\n",
        "                names, _ = tokenize_with_spacy(essay['NAME_STUDENT'].lower())\n",
        "                labels = assign_name(names, tokens, labels)\n",
        "        elif label_type == 'STREET_ADDRESS':\n",
        "            address = essay['STREET_ADDRESS'].lower().replace(\"\\\\n\", \" \")\n",
        "            # print(f\"address {address}\")\n",
        "            address = address.translate(str.maketrans('', '', string.punctuation)) # Remove punctuations\n",
        "            address = address.split(' ')\n",
        "            if len(address) > 0:\n",
        "                labels = assign_street_address(address, tokens, labels)\n",
        "        elif label_type == 'PHONE_NUM':\n",
        "            phones, _ = tokenize_with_spacy(essay['PHONE_NUM'].lower())\n",
        "            labels, isFirst_flags = assign_phone_number(phones, tokens, labels, isFirst_flags)\n",
        "        elif label_type == 'EMAIL':\n",
        "            email = essay['EMAIL'].lower()\n",
        "            assign_email(email, tokens, labels)\n",
        "        elif label_type == 'USERNAME':\n",
        "            username = essay['USERNAME'].lower()\n",
        "            assign_username(username, tokens, labels)\n",
        "        else:\n",
        "            labels, isFirst_flags = assign_other_label_types(essay, label_type, tokens,\n",
        "                                                             labels, isFirst_flags)\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3Jwv33bu-XOf"
      },
      "outputs": [],
      "source": [
        "def process_full_text(full_text):\n",
        "    if 'Unprocessed:' in full_text: # Need to split the instruction and response\n",
        "        pattern = r'([*]*Please write an essay about [^*]*[*]*)'\n",
        "        x = re.search(pattern, full_text)\n",
        "        if x:\n",
        "            splits = re.split(pattern, full_text)\n",
        "            text = splits[-1].strip()\n",
        "            # print(f\"=== Split text ===\\n {text}\")\n",
        "            return text\n",
        "        else:\n",
        "            print(f\"### UnProcess text###\\n {full_text}\")\n",
        "            return None\n",
        "    else:\n",
        "        return full_text.strip() # Remove the space to the left\n",
        "\n",
        "# Map the label to token\n",
        "def create_token_map(tokens, labels):\n",
        "    token_map = []\n",
        "    for i, label in enumerate(labels):\n",
        "        if label != 'O':\n",
        "            token_map.append({label: (tokens[i], i)})\n",
        "    return token_map"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_full_text(full_text):\n",
        "    if isinstance(full_text, str) and 'Unprocessed:' in full_text: # Need to split the instruction and response\n",
        "        pattern = r'([*]*Please write an essay about [^*]*[*]*)'\n",
        "        x = re.search(pattern, full_text)\n",
        "        if x:\n",
        "            full_text = full_text.replace(x.group(1), '')\n",
        "    return full_text\n"
      ],
      "metadata": {
        "id": "gg_AvlzpShZW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer\n",
        "en_tokenizer = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to tokenize text with Spacy tokenizer\n",
        "def tokenize_with_spacy(text, tokenizer=en_tokenizer):\n",
        "    try:\n",
        "        # Check if text is a string\n",
        "        if not isinstance(text, str):\n",
        "            # If not a string, convert to string\n",
        "            text = str(text)\n",
        "        tokenized_text = tokenizer(text)\n",
        "        tokens = [token.text for token in tokenized_text]\n",
        "        trailing_whitespace = [bool(token.whitespace_) for token in tokenized_text]\n",
        "        return tokens, trailing_whitespace\n",
        "    except Exception as e:\n",
        "        # Handle any errors or exceptions\n",
        "        print(\"Error occurred during tokenization:\", e)\n",
        "        return [], []\n",
        "\n",
        "# Example usage\n",
        "full_text = \"This is some text to tokenize.\"\n",
        "tokens, trailing_whitespace = tokenize_with_spacy(full_text)\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Trailing whitespace:\", trailing_whitespace)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jElAQhK2TDMS",
        "outputId": "358ec4b4-a71f-4010-d8ed-6291de824c93"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['This', 'is', 'some', 'text', 'to', 'tokenize', '.']\n",
            "Trailing whitespace: [True, True, True, True, True, False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FMY3nCZEUqW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the labels to the tokens\n",
        "results = []\n",
        "doc_id = 1_221_555_000 # document id\n",
        "for i in range(len(generated_df)):\n",
        "    row = generated_df.iloc[i]\n",
        "    full_text = process_full_text(row[\"Essay\"])\n",
        "    if full_text:\n",
        "        # Tokenize the text using spacy tokenizer\n",
        "        tokens, trailing_whitespace = tokenize_with_spacy(full_text)\n",
        "        labels = assign_labels(row, tokens)\n",
        "        token_map = create_token_map(tokens, labels)\n",
        "        doc_id += 1\n",
        "        result = {\n",
        "            'document': doc_id,\n",
        "            'full_text': full_text,\n",
        "            'tokens': tokens,\n",
        "            'trailing_whitespace': trailing_whitespace,\n",
        "            'labels': labels,\n",
        "            'token_map': token_map\n",
        "        }\n",
        "        # Add PII to result\n",
        "        for label_type in label_types:\n",
        "            result[label_type] = row[label_type]\n",
        "        # print(result)\n",
        "        results.append(result)\n",
        "# # Save to temp fold for verification\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"temp/pii_dataset_Gemma.csv\", index=False, encoding=\"UTF-8\")\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ll1wA0uNWoVF",
        "outputId": "6a9bb474-10d1-486c-8ae4-4638172bb0a3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-ae02e34bb187>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Tokenize the text using spacy tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrailing_whitespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_with_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtoken_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_token_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdoc_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-85e79643ea32>\u001b[0m in \u001b[0;36massign_labels\u001b[0;34m(essay, tokens)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Check if the value is not NaN and is a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NAME_STUDENT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_with_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NAME_STUDENT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlabel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'STREET_ADDRESS'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-48aba80a85bd>\u001b[0m in \u001b[0;36mtokenize_with_spacy\u001b[0;34m(text, tokenizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# If not a string, convert to string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrailing_whitespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhitespace_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \"\"\"\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/ml/tb_framework.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     step_model = ParserStepModel(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/ml/parser_model.pyx\u001b[0m in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ragged_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_padded_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6wVggR_LYAv7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5cb969d61b874891848e63e48644c6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fe4f31be673447dabcb40313c0c62ca",
              "IPY_MODEL_abf4ba9bcdc34f0db15d91fdccb86844",
              "IPY_MODEL_d991d906dd724703b87fbf3c1d9cf764"
            ],
            "layout": "IPY_MODEL_7668c44a68d946fb931d51a251329aa9"
          }
        },
        "5fe4f31be673447dabcb40313c0c62ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ac2735f5374e209dd38d9fab22bdfa",
            "placeholder": "​",
            "style": "IPY_MODEL_cc1c412f288d478aa364fc3fe4fb6111",
            "value": "100%"
          }
        },
        "abf4ba9bcdc34f0db15d91fdccb86844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fed3cd73b3a47bebacf57945c49609f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e662454e695b456d9a5c4fd2049b446e",
            "value": 100
          }
        },
        "d991d906dd724703b87fbf3c1d9cf764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffbb7d31157e46b6a21df97898c405d9",
            "placeholder": "​",
            "style": "IPY_MODEL_6899348464ec4690836c02c18eac3782",
            "value": " 100/100 [00:39&lt;00:00,  3.00it/s]"
          }
        },
        "7668c44a68d946fb931d51a251329aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ac2735f5374e209dd38d9fab22bdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1c412f288d478aa364fc3fe4fb6111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fed3cd73b3a47bebacf57945c49609f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e662454e695b456d9a5c4fd2049b446e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffbb7d31157e46b6a21df97898c405d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6899348464ec4690836c02c18eac3782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d28e42dc4326427c93d9640e843b56ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5284cda3ff764f3e8dd116772e2b79c0",
              "IPY_MODEL_9569f011af4146c8b936c26743330374",
              "IPY_MODEL_fdc62045148f477ab33c16f418e7346c"
            ],
            "layout": "IPY_MODEL_06fab88c074b487d8abe8688515680c8"
          }
        },
        "5284cda3ff764f3e8dd116772e2b79c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6984e7cb4f904203a74488e03eb1e423",
            "placeholder": "​",
            "style": "IPY_MODEL_f1f1a9a9d4d343fa9d6820faf0fe4bd0",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "9569f011af4146c8b936c26743330374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f49b1affc54fb192cd70ab2b0c64c7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1ccd7c44794497f8b76ce4b92785fce",
            "value": 0
          }
        },
        "fdc62045148f477ab33c16f418e7346c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c934e5d6fe44d5d92ffd7d779815af5",
            "placeholder": "​",
            "style": "IPY_MODEL_f2cd9f68b81944608f9b5092ee21c5f0",
            "value": " 0/2 [08:04&lt;?, ?it/s]"
          }
        },
        "06fab88c074b487d8abe8688515680c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6984e7cb4f904203a74488e03eb1e423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f1a9a9d4d343fa9d6820faf0fe4bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f49b1affc54fb192cd70ab2b0c64c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ccd7c44794497f8b76ce4b92785fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c934e5d6fe44d5d92ffd7d779815af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2cd9f68b81944608f9b5092ee21c5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}